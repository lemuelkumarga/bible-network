{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Social Networks in the Bible\n",
    "\n",
    "<h4 class=\"author\"><span class=\"meta\">Lemuel Kumarga</span></h4>\n",
    "<h4 class=\"date\"><span class=\"meta\">Apr 2018</span></h4>\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "Social circles form huge parts of our lives. They include individuals that we interact with, how often we interact with them and the mode of communication used for interactions. With the rise of digital communication and networking, these interactions are carefully recorded through the use of modern tools and algorithms. A brief look at our social networking sites, such as Facebook and LinkedIn, allows us to easily gather information that characterizes our social circles, such as network of friends, frequency of communication, etc. \n",
    "\n",
    "Unfortunately, information about our social circles has not always been as readily available. People who lived before the 21st century did not have access to the data-rich information of digital communication, nor did they have the tools to analyze large quantities of daily interactions. However, by synthesizing modern concepts with historical records, we could potentially unearth some information regarding these individuals' social circles. In the case of this project, we will use Natural Language Processing (NLP) to <span class=\"hl\">construct a social network for the bible</span>.\n",
    "\n",
    "To skip the methodology and proceed straight into the network, please click <a href=\"#The-Social-Network\">here</a>.\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "First load the necessary modules for this exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('shared/')\n",
    "import defaults as _d\n",
    "import helper as _h\n",
    "\n",
    "# Load All Main Modules\n",
    "_d.load({\"pd\":\"pandas\",\n",
    "         \"math\":\"math\",\n",
    "         \"cl\":\"collections\",\n",
    "         \"np\":\"numpy\",\n",
    "         \"sp\":\"scipy\",\n",
    "         \"re\":\"re\",\n",
    "         \"mpl\":\"matplotlib\",\n",
    "         \"plotly\":\"plotly\",\n",
    "         \"nltk\":\"nltk\",\n",
    "         \"wordcloud\":\"wordcloud\",\n",
    "         \"PIL\":\"PIL\",\n",
    "         \"operator\":\"operator\",\n",
    "         \"nx\":\"networkx\",\n",
    "         \"sklearn\":\"sklearn\",\n",
    "         \"random\":\"random\"},\n",
    "         globals())\n",
    "\n",
    "# Load All Submodules\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as py_go\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "# If you can't find the module, run nltk.download() in python\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "_d.stylize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will construct helper functions to be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# Genre-Related Functions\n",
    "# -------------------------------------\n",
    "def __get_genre_groups():\n",
    "    global _genre_group\n",
    "    if \"_genre_group\" not in globals():\n",
    "        _genre_group = bible.groupby(\"Genre\",sort=False)\n",
    "    return _genre_group\n",
    "\n",
    "def __get_genre_colors():\n",
    "    global _genre_colors\n",
    "    if \"_genre_colors\" not in globals():\n",
    "        color_pal = _d.get_color(\"palette\")(len(__get_genre_groups()))\n",
    "        color_dict = dict()\n",
    "        ind = 0\n",
    "        for name, _ in __get_genre_groups():\n",
    "            color_dict[name] = color_pal[ind]\n",
    "            ind += 1\n",
    "        _genre_colors = color_dict\n",
    "    return _genre_colors\n",
    "\n",
    "def __get_genre_legends(rev = True):\n",
    "    global _genre_legends\n",
    "    global _genre_legends_rev\n",
    "    if \"_genre_legends\" not in globals():\n",
    "        _genre_legends = [mpatches.Patch(color=_d.bg_color,label=\"Genre\")]\n",
    "        for name, group in __get_genre_groups():\n",
    "            legend_text = name + \" (\" + group.index[0]\n",
    "            if (len(group.index) > 1):\n",
    "                legend_text += \" - \" + group.index[-1]\n",
    "            legend_text += \")\"\n",
    "            _genre_legends.append(mpatches.Patch(color=__get_genre_colors()[name], label=legend_text))\n",
    "        _genre_legends_rev = _genre_legends[:0:-1]\n",
    "        _genre_legends_rev.insert(0,_genre_legends[0])\n",
    "    \n",
    "    if rev:\n",
    "        return _genre_legends_rev\n",
    "    else:\n",
    "        return _genre_legends\n",
    "\n",
    "# -------------------------------------\n",
    "# Word-Cloud Related Functions\n",
    "# -------------------------------------\n",
    "def __word_cloud(input, fig_size = (20,10), image = None, colors = None):\n",
    "    \n",
    "    # Step 1: If there is an image specified, we need to create a mask\n",
    "    mask = None\n",
    "    if (image != None):\n",
    "        mask = np.array(PIL.Image.open(image))\n",
    "        if (colors == \"image_colors\"):\n",
    "            colors = wordcloud.ImageColorGenerator(mask)\n",
    "    \n",
    "    # Step 2: Set up default colors\n",
    "    def_colors = mpl.colors.ListedColormap(_d.get_color())\n",
    "    \n",
    "    # Step 3: Generate Word Cloud\n",
    "    #https://stackoverflow.com/questions/43043437/wordcloud-python-with-generate-from-frequencies\n",
    "    wc = wordcloud.WordCloud(height=fig_size[1]*100,\n",
    "                             width=fig_size[0]*100,\n",
    "                             font_path=\"fonts/{}.ttf\".format(_d.def_font),\n",
    "                             background_color=_d.bg_color,\n",
    "                             mask = mask,\n",
    "                             colormap = def_colors,\n",
    "                             color_func = colors).generate_from_frequencies(input)\n",
    "\n",
    "    # Step 4: Plot Word Cloud\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def __wc_color_func(character_freq_by_genre):\n",
    "    # Create color functions to determine the genre most associated with the character\n",
    "    def color_func(word, font_size, position, orientation, **kwargs):\n",
    "        most_common_genre = character_freq_by_genre[word].most_common(1)[0][0]\n",
    "        intensity = 1. * character_freq_by_genre[word][most_common_genre] / sum(character_freq_by_genre[word].values())\n",
    "        return _d.pollute_color(__min_color, __get_genre_colors()[most_common_genre],intensity)\n",
    "    \n",
    "    return color_func\n",
    "    \n",
    "__get_legend_separator = mpatches.Patch(color=_d.bg_color,label=\"\")    \n",
    "    \n",
    "def __get_minmax_legends(input, title, key_format = \"{:.2f}\"):\n",
    "    output = []\n",
    "    output.append(mpatches.Patch(color=_d.bg_color,label=title))\n",
    "    max_item = max(input.items(), key=operator.itemgetter(1))\n",
    "    output.append(mlines.Line2D([0], [0], marker='o', color=_d.bg_color, label=\"Max: \" + key_format.format(max_item[1]) + \" - \" + max_item[0],\n",
    "                      markerfacecolor=_d.ltxt_color, markersize=20))\n",
    "    min_item = min(input.items(), key=operator.itemgetter(1))\n",
    "    output.append(mlines.Line2D([0], [0], marker='o', color=_d.bg_color, label=\"Min: \" + key_format.format(min_item[1]) + \" - \" + min_item[0],\n",
    "                      markerfacecolor=_d.ltxt_color, markersize=10))\n",
    "    return output\n",
    "\n",
    "__min_color = _d.pollute_color(_d.bg_color,_d.txt_color,0.4)\n",
    "def __get_saturate_legends(title):\n",
    "    output = []\n",
    "    output.append(mpatches.Patch(color=_d.bg_color,label=title))\n",
    "    output.append(mpatches.Patch(color=_d.get_color(0),label=\"Concentrated In 1 Genre\"))\n",
    "    output.append(mpatches.Patch(color=_d.pollute_color(__min_color,_d.get_color(0),0.3), label=\"Spread Out Across\\nMultiple Genres\"))\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "In this exercise, we will be using the bible <a data-toggle=\"popover\" title=\"\" data-content=\"A collection of texts\" data-original-title=\"Corpus\">corpus</a> from <a href=\"https://www.kaggle.com/oswinrh/bible/data\" target=\"_blank\">Kaggle.</a> The data will be stored in abbreviated book keys, with each book containing the following attributes:\n",
    "\n",
    "* <span class=\"hl\">Book Name</span>: Full name of the book\n",
    "* <span class=\"hl\">Testament</span>: New (NT) or old (OT)\n",
    "* <span class=\"hl\">Genre</span>: Genre of the book\n",
    "* <span class=\"hl\">Chapters</span>: Number of chapters\n",
    "* <span class=\"hl\">Verses</span>: Total number of verses\n",
    "* <span class=\"hl\">Text</span>: The actual text of the book\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all book statistics\n",
    "abb = pd.read_csv(\"data/key_abbreviations_english.csv\")\\\n",
    "        .query('p == 1')[[\"a\",\"b\"]]\\\n",
    "        .rename(columns={\"a\" : \"Key\"})\n",
    "ot_nt = pd.read_csv(\"data/key_english.csv\")\\\n",
    "          .rename(columns={\"n\" : \"Name\", \"t\" : \"Testament\"})\n",
    "genres = pd.read_csv(\"data/key_genre_english.csv\")\\\n",
    "           .rename(columns={\"n\" : \"Genre\"})\n",
    "\n",
    "# Load the main biblical text\n",
    "bible = pd.read_csv(\"data/t_asv.csv\")\\\n",
    "          .groupby(\"b\", as_index=False)\\\n",
    "          .agg({\"c\": pd.Series.nunique, \"v\": \"size\", \"t\":\" \".join})\\\n",
    "          .rename(columns={\"c\": \"Chapters\",\"v\": \"Verses\",\"t\": \"Text\"})\n",
    "# Perform some cleaning\n",
    "bible['Text'] = bible['Text'].apply(lambda t: re.sub(\"[`]|['][^s]\",\"\",t))\n",
    "\n",
    "# Join the remaining book statistics\n",
    "bible = bible.join(abb.set_index('b'), on='b')\\\n",
    "             .join(ot_nt.set_index('b'), on='b')\\\n",
    "             .join(genres.set_index('g'), on='g')\\\n",
    "             .drop(['b', 'g'], axis=1)\\\n",
    "             .set_index('Key')\\\n",
    "             [[\"Name\",\"Testament\",\"Genre\",\"Chapters\",\"Verses\",\"Text\"]]\n",
    "            \n",
    "# Show the first few lines\n",
    "bible.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### About the Data\n",
    "\n",
    "We will also derive some language statistics from each book, mainly:\n",
    "\n",
    "* <span class=\"hl\">Sentences</span>: Number of sentences in the book, and\n",
    "* <span class=\"hl\">Words</span>: Number of words in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Sentences and Words columns\n",
    "bible[\"Sentences\"] = pd.Series(0, index=bible.index)\n",
    "bible[\"Words\"] = pd.Series(0, index=bible.index)\n",
    "\n",
    "# Save Tokens\n",
    "def get_tokens():\n",
    "    sent_tokens = OrderedDict()\n",
    "    word_tokens = OrderedDict()\n",
    "    for i, r in bible[[\"Text\"]].iterrows():\n",
    "        txt = r.str.cat()\n",
    "        sent_tokens[i] = sent_tokenize(txt)\n",
    "        word_tokens[i] = word_tokenize(txt)\n",
    "    return (sent_tokens, word_tokens)\n",
    "\n",
    "sent_tokens, word_tokens = _h.cache(get_tokens, \"bible_tokens\")\n",
    "\n",
    "for i in bible.index:\n",
    "    bible.at[i,'Sentences'] = len(sent_tokens[i])\n",
    "    # Remove Punctuation\n",
    "    bible.at[i,'Words'] = len([w for w in word_tokens[i] if re.match('\\w+',w)])\n",
    "\n",
    "# Show\n",
    "bible[[\"Name\",\"Testament\",\"Genre\",\"Chapters\",\"Verses\",\"Sentences\",\"Words\"]].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book Length\n",
    "\n",
    "One of the most intuitive ways to understand the books' uneven distribution is to assume that we are doing devotions each chapter a day. Under such a scenario, we will have the following timeline:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "    \n",
    "# Create Plots\n",
    "yticks = []\n",
    "ylabels = []\n",
    "x_progress = 0\n",
    "x_length = sum(bible[\"Chapters\"])\n",
    "y_progress = 0\n",
    "y_length = len(bible[\"Chapters\"])               \n",
    "for name, group in __get_genre_groups():\n",
    "\n",
    "    row_ids = [ bible.index.get_loc(i) for i in group.index ]\n",
    "\n",
    "    # Part 1: Bars When Genre Is Still Being Read\n",
    "    length = 0\n",
    "    # For each book in the genre\n",
    "    for idx in row_ids:\n",
    "\n",
    "        # If we are reading this book in the anniversary \n",
    "        if (math.floor((x_progress + length)/365) < math.floor((x_progress + length + bible[\"Chapters\"][idx])/365)):\n",
    "            yticks.append(idx + 1)\n",
    "            ylabels.append(\"{} ({}%)\".format(bible.index[idx],round(idx/y_length * 100)))\n",
    "\n",
    "        plt.broken_barh([(x_progress + length, bible[\"Chapters\"][idx])],\n",
    "                        (y_progress, (idx + 1) - y_progress),\n",
    "                        facecolors = __get_genre_colors()[name])\n",
    "        length += bible[\"Chapters\"][idx]\n",
    "    \n",
    "    \n",
    "    # Part 2: Bars When Genre has Been Read\n",
    "    plt.broken_barh([(x_progress + length, x_length - x_progress - length)],\n",
    "                    (y_progress, max(row_ids) + 1 - y_progress), \n",
    "                    facecolors = __get_genre_colors()[name])\n",
    "    \n",
    "    x_progress += length\n",
    "    y_progress = max(row_ids) + 1\n",
    "    \n",
    "\n",
    "# Add Titles and Grid\n",
    "plt.title(\"Chapter Distribution by Book\")\n",
    "plt.grid(color=_d.fade_color(_d.ltxt_color,0.5), linestyle='dashed')\n",
    "\n",
    "# Add X-Axis Details\n",
    "plt.xlabel(\"Time Since Start\")\n",
    "xticks = [365, 2 * 365, 3 * 365 ,sum(bible[\"Chapters\"])]\n",
    "xlabels = [ \"Year 1\", \"Year 2\", \"Year 3\", \"Year 3\\nMonth 3\" ]\n",
    "plt.xticks(xticks, xlabels)\n",
    "plt.xlim(0,x_length)\n",
    "\n",
    "# Add Y-Axis Details\n",
    "yticks.append(y_length)\n",
    "ylabels.append(\"{} ({}%)\".format(bible.index[-1],round(1 * 100)))\n",
    "plt.ylabel(\"% of Books Completed\")\n",
    "plt.yticks(yticks, ylabels)\n",
    "plt.ylim(0, y_length)\n",
    "\n",
    "# Add Legends\n",
    "plt.legend(handles=__get_genre_legends(), bbox_to_anchor=[1.27, 1.0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the 1st year, we would have only completed 18% of the bible. If this is not discouraging enough, after a further year, we would still not have completed the Old Testament (<span class=\"yellow-text\">Law</span> to <span class=\"red-text\">Prophets</span>). However, upon reaching the New Testament (<span class=\"blue-text\">Gospels</span> to <span class=\"green-text\">Apocalyptic</span>), we could complete the whole set of books within 9 months. The Old Testament is deceivingly at least 3 times longer than the New Testament!\n",
    "\n",
    "####  Chapter Length\n",
    "\n",
    "Assuming that the average human reads <a href=\"http://www.readingsoft.com/\" target=\"_blank\">200 words per minute</a>, we can also estimate how long it will take to read 1 chapter a day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible[\"Minutes_p_Chapter\"] = bible[\"Words\"] / bible[\"Chapters\"] / 200.\n",
    "inputs = []\n",
    "\n",
    "deg_incr = 360. / len(bible.index)\n",
    "for name, group in __get_genre_groups():\n",
    "    \n",
    "    # Insert Legend Item\n",
    "    inputs.append(\n",
    "        py_go.Scatterpolar(\n",
    "            r = [0, 0, 0, 0],\n",
    "            theta = [0, 0, 0, 0],\n",
    "            name = name,\n",
    "            legendgroup = name,\n",
    "            mode = 'none',\n",
    "            fill = 'toself',\n",
    "            fillcolor = __get_genre_colors()[name],\n",
    "            showlegend = True\n",
    "        )\n",
    "    \n",
    "    )    \n",
    "    \n",
    "    # Insert Each Book\n",
    "    for key, val in group[\"Minutes_p_Chapter\"].items():\n",
    "        inputs.append(\n",
    "            py_go.Scatterpolar(\n",
    "                r = [0, val, val, 0],\n",
    "                theta = [0,bible.index.get_loc(key)*deg_incr,(bible.index.get_loc(key)+1)*deg_incr,0],\n",
    "                name = bible[\"Name\"][key],\n",
    "                legendgroup = name,\n",
    "                mode = 'none',\n",
    "                hoverinfo ='text',\n",
    "                text=bible[\"Name\"][key] + \": \" + \"{:.1f}\".format(val) + \" min\",\n",
    "                fill = 'toself',\n",
    "                fillcolor = __get_genre_colors()[name],\n",
    "                showlegend = False\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "layout = py_go.Layout(_d.py_layout)\n",
    "layout[\"autosize\"] = False\n",
    "layout[\"width\"] = 450\n",
    "layout[\"height\"] = 350\n",
    "layout[\"margin\"] = dict(t=80,l=0,r=0,b=20)\n",
    "layout[\"title\"] = \"Minutes Required to Read a Chapter\"\n",
    "layout[\"polar\"][\"angularaxis\"][\"visible\"]=False\n",
    "\n",
    "fig = py_go.Figure(data=inputs, layout=layout)\n",
    "py.iplot(fig, config=_d.py_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the chart above, we conclude that chapter lengths across books are varied as well. For example, a chapter in <span class=\"hl orange-text\">1 Kings</span> will take around 5.5 minutes to read, while a chapter in <span class=\"hl red-text\">Psalms</span> will take around 1.5 minutes. \n",
    "\n",
    "### Preliminary Insights\n",
    "\n",
    "After obtaining an overview of the bible, we move to investigate the occurrences of various characters in the book.\n",
    "\n",
    "#### The Trinity\n",
    "\n",
    "The first point of interest is how much God appears at different books in the bible:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_occurence(regex):\n",
    "    output = OrderedDict()\n",
    "    for name, group in __get_genre_groups():\n",
    "        l = [len(re.findall(regex,wt.str.cat())) for _, wt in group[[\"Text\"]].iterrows()]\n",
    "        output[name] = (len(l),sum(l)/len(l))\n",
    "    return output\n",
    "\n",
    "entityToSearch = OrderedDict([('God', 'God|Lord|GOD|LORD'),\n",
    "                              ('Father','Jehovah|Father'),\n",
    "                              ('Son','Jesus|Christ|Emmanuel'),\n",
    "                              ('Spirit','Spirit')])\n",
    "\n",
    "ind = 0\n",
    "# Construct Plots for Each Entity\n",
    "f, splt = plt.subplots(1,len(entityToSearch.items()), figsize=(20,5))\n",
    "for title, regex in entityToSearch.items():\n",
    "    occurences = find_occurence(regex)\n",
    "    splt[ind].set_title(title)\n",
    "    splt[ind].set_xticks([])\n",
    "    splt[ind].set_yticks([])\n",
    "    x = 0\n",
    "    for n, v in occurences.items():\n",
    "        splt[ind].bar([x + v[0]/2],\n",
    "                      [v[1]],\n",
    "                      color = __get_genre_colors()[n],\n",
    "                      width = v[0])\n",
    "        x += v[0]\n",
    "    ind += 1\n",
    "\n",
    "# Insert Legends\n",
    "plt.legend(handles=__get_genre_legends(False), bbox_to_anchor = [2.2, 1.05])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, words associated with God the Father (Jehovah/Father) appear prominently in the Old Testament, while words associated with God the Son (Jesus/Christ) hit high frequencies in the Gospel narratives. Word counts of the Spirit appear the highest in Acts. This sequence is in line with the story of the Gospel, where the events first transcribed were between God the Father and His people, followed by Jesus Christ and his believers, and finally with the Holy Spirit and the church.\n",
    "\n",
    "(Note: One limitation of such an approach is the failure to capture symbols pointing to God. For example, words such as \"Lamb\" in Revelations correspond to Christ, but such symbols were excluded as they would introduce false positives.)\n",
    "\n",
    "#### Major Characters\n",
    "\n",
    "Using <a href=\"http://bibleblender.com/2014/biblical-lessons/biblical-history/complete-list-of-major-minor-characters-in-bible\" target=\"_blank\">external sources</a>, we can also obtain a list of major characters in the bible. This list can then be used as a reference for detecting names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characters obtained from http://bibleblender.com/2014/biblical-lessons/biblical-history/complete-list-of-major-minor-characters-in-bible\n",
    "characters_regex = 'Adam|Seth|Enos|Kenan|Mahalalel|Jared|Enoch|Methuselah|Lamech|Noah|Shem|Adam|Cain|Enoch|Irad|Mehujael|Methusael|Lamech|Tubal-cain|Arpachshad|Shelah|Eber|Peleg|Reu|Serug|Nahor|Terah|Abraham|Isaac|Jacob|Judah|Perez|Hezron|Ram|Amminadab|Nahshon|Salmon|Boaz|Obed|Jesse|David|Abel|Kenan|Enoch|Noah |Abraham|Isaac|Jacob|Joseph|Sarah|Rebecca|Rachel|Leah|Moses|Aaron|Miriam|Eldad|Medad|Phinehas|Joshua|Deborah|Gideon|Eli|Elkanah|Hannah|Abigail|Samuel|Gad|Nathan|David|Solomon|Jeduthun|Ahijah|Elijah|Elisha|Shemaiah|Iddo|Hanani|Jehu|Micaiah|Jahaziel|Eliezer|Zechariah|Huldah|Isaiah|Jeremiah|Ezekiel|Daniel|Hosea|Joel|Amos|Obadiah|Jonah|Micah|Nahum|Habakkuk|Zephaniah|Haggai|Zechariah|Malachi|Beor|Balaam|Job|Amoz|Beeri|Baruch|Agur|Uriah|Buzi|Mordecai|Esther|Oded|Azariah|Abimelech|Saul|Ish-boseth|David|Solomon|Jeroboam|Nadab|Baasha|Elah|Zimri|Tibni|Omri|Ahab|Ahaziah|Jehoram|Jehu|Jehoahaz|Jehoash|Jeroboam|Zechariah|Shallum|Menahem|Pekahiah|Pekah|Hoshea|Rehoboam|Abijam|Asa|Jehoshaphat|Jehoram|Ahaziah|Athaliah|Jehoash|Amaziah|Uzziah|Jotham|Ahaz|Hezekiah|Manasseh|Amon|Josiah|Jehoahaz|Jehoiakim|Jeconiah|Zedekiah|Simon|John|Aristobulus|Alexander|Hyrcanus|Aristobulus|Antigonus|Herod|Herod|Herod|Philip|Salome|Agrippa|Agrippa|Simon|Aaron|Eleazar|Eli|Phinehas|Asher|Benjamin|Dan|Gad|Issachar|Joseph|Ephraim|Manasseh|Judah|Levi|Naphtali|Reuben|Simeon|Zebulun|Jesus|Mary|Joseph|James|Jude|Joses|Simon|Peter|Andrew|James|John|Philip|Bartholomew|Thomas|Matthew|James|Judas|Simon|Judas|Matthias|Paul|Barnabas|James|Jude|Caiaphas|Annas|Zechariah|Agabus|Anna|Simeon|John|Apollos|Aquila|Dionysius|Epaphras|Joseph|Lazarus|Luke|Mark|Martha|Mary|Mary|Nicodemus|Onesimus|Philemon'\n",
    "character_freq = []\n",
    "for name, group in __get_genre_groups():\n",
    "    names = [re.findall(characters_regex,wt.str.cat()) for _, wt in group[[\"Text\"]].iterrows()]\n",
    "    l = [(w,name) for l in names for w in l]\n",
    "    character_freq.extend(l)\n",
    "\n",
    "# The frequency of each character occurence by genre\n",
    "character_freq = nltk.ConditionalFreqDist(character_freq)\n",
    "\n",
    "# Plot word cloud for each name\n",
    "inputs = {}\n",
    "for n, fd in character_freq.items():\n",
    "    inputs[n] = sum(fd.values())\n",
    "__word_cloud(inputs, colors=__wc_color_func(character_freq))\n",
    "\n",
    "# Titles\n",
    "plt.title(\"Major Character Occurences\")\n",
    "\n",
    "# Legends\n",
    "legend_cloud = list(__get_genre_legends(False))\n",
    "legend_cloud.append(__get_legend_separator)\n",
    "legend_cloud.extend(__get_saturate_legends(\"Concentration\"))\n",
    "legend_cloud.append(__get_legend_separator)\n",
    "legend_cloud.extend(__get_minmax_legends(inputs, \"Word Count\",\"{:d}\"))\n",
    "plt.legend(handles=legend_cloud, bbox_to_anchor = [1.31, 1.])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph, <span class=\"hl orange-text\">David</span> appears the most in the bible. In addition, his appearances are concentrated within the <span class=\"hl orange-text\">History</span> genre. This is in stark-contrast to <span class=\"hl\">Jesus</span>, whose name appeared across multiple genres.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "In order to construct a social network, we first need to identify relevant characters in the bible. One approach is to find a list of names from external sources, and then use that to identify the names. However, this method is <span class=\"hl\">unscalable</span>. To illustrate, suppose we would like to construct a similar network for \"Oliver Twist\". Then, we would need to find a list of names associated with the book. But what happens if we are not able to find such a list?\n",
    "\n",
    "Therefore, to reduce reliance on external sources, we need to develop a more robust approach for name-identification.\n",
    "\n",
    "### Finding the Entities\n",
    "\n",
    "Fortunately, we are able to capture names due to the nature of English linguistics. Names fall under the category of \"Proper Nouns\", which we can detect using <a href=\"https://en.wikipedia.org/wiki/Part-of-speech_tagging\" target=\"_blank\">Part-of-Speech (POS) tagging</a>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proper_noun_tokens():\n",
    "    tagged_word_tokens = OrderedDict((n, nltk.tag.pos_tag(wt)) for n, wt in word_tokens.items())\n",
    "    # Extract Only Proper Nouns and Add Index\n",
    "    proper_noun_tokens = OrderedDict((n, [(i, w[0]) for i, w in enumerate(wt) if w[1] == \"NNP\"]) for n, wt in tagged_word_tokens.items())\n",
    "    return proper_noun_tokens\n",
    "proper_noun_tokens = _h.cache(get_proper_noun_tokens, \"ppn_tokens\")\n",
    "    \n",
    "# Print 100 Most Common Words\n",
    "noun_freq = nltk.FreqDist(w for n,wt in proper_noun_tokens.items() for i, w in wt)\n",
    "\", \".join([n for n, v in noun_freq.most_common(50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the text above, we have captured a majority of names in the bible. However, there are also some false positives such as <span class=\"hl\">O, Go, Thy, Ye</span> that need to be removed. It is also interesting to see entities other than people being detected (e.g. <span class=\"hl\">Jerusalem, Babylon</span>).\n",
    "\n",
    "### Managing the Cases\n",
    "\n",
    "The first case to handle is the occurrence of words which are not proper nouns (<span class=\"hl\">O, Go, Thy, Ye</span>). To solve this, we simply need to exclude them from consideration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_npp = ['O','Thou','Behold','Go','Thy','Ye','My','A','Yea','Thus','Come',\n",
    "             'Therefore','Wherefore','Be','So','Hear','ye','Psalm','Selah','Arise','Woe','King','Speak',\n",
    "             'Almighty','Who','How','Chief','thy','Fear','Musician','Which','High','Take','Most',\n",
    "             'Shall','Lo','Let','Praise','Make','Nay','Say','River','Art','Amen','South','Lest',\n",
    "             'Bring','Oh','Remember','Did','Teacher','Sea','Whosoever','Do','Every','Unto','Know',\n",
    "             'Are','Mine','See','Tell','Whoso','Gods','Wilt','Red','Holy','[',']','Mount', 'TR','Please',\n",
    "             'Tent','Man','Passover','Meeting','Will','Again','Whoever','Savior','Ai','No','May','Heaven',\n",
    "             'Whose','unto','Ah','Bless','Ascribe','Return','Seek','Day','Night','journeyed','Sit','Feed','Sirs','Prepare',\n",
    "             'Good','Follow','Psalmof','Render']\n",
    "# Extract Only Proper Nouns and Add Index\n",
    "proper_noun_tokens = OrderedDict((n, [(i, w) for i, w in wt if w not in false_npp]) for n, wt in proper_noun_tokens.items())\n",
    "# Print 100 Most Common Words after excluding False Proper Nouns\n",
    "noun_freq = nltk.FreqDist(w for n,wt in proper_noun_tokens.items() for i, w in wt)\n",
    "\", \".join([n for n, v in noun_freq.most_common(50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second case to consider is non-human entities. Some examples of these are nations (<span class=\"hl\">Jerusalem, Babylon</span>), locations (<span class=\"hl\">Galilee</span>), symbols (<span class=\"hl\">Lord, Father, Son</span>) and false idols (<span class=\"hl\">Baal</span>). Since the relationships between non-human entities can yield useful insights, we will not be excluding such words and instead expand our scope from humans to entities.\n",
    "\n",
    "### The Entity Cloud\n",
    "\n",
    "Using the <span class=\"hl\">Proper Noun</span> approach, we can subsequently plot these entities into a word cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The frequency of each character occurence by genre\n",
    "character_freq = nltk.ConditionalFreqDist((w[1],bible[\"Genre\"][n]) for n,wt in proper_noun_tokens.items() for w in wt)\n",
    "\n",
    "# Plot word cloud for each name\n",
    "inputs = {}\n",
    "for n, fd in character_freq.items():\n",
    "    inputs[n] = sum(fd.values())\n",
    "__word_cloud(inputs, colors=__wc_color_func(character_freq))\n",
    "\n",
    "# Titles\n",
    "plt.title(\"Entities in the Bible\")\n",
    "\n",
    "# Legends\n",
    "legend_cloud = list(__get_genre_legends(False))\n",
    "legend_cloud.append(__get_legend_separator)\n",
    "legend_cloud.extend(__get_saturate_legends(\"Concentration\"))\n",
    "legend_cloud.append(__get_legend_separator)\n",
    "legend_cloud.extend(__get_minmax_legends(inputs, \"Word Count\",\"{:d}\"))\n",
    "plt.legend(handles=legend_cloud, bbox_to_anchor = [1.31, 1.])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we have now expanded the set of major characters (<span class=\"orange-text\">David</span>, <span class=\"purple-text\">Jesus</span>) into a larger entity of names, nations and symbols (amongst others). There are also some interesting patterns emerging. For once, the word <span class=\"purple-text hl\">Jesus</span> is dispersed across multiple genres, while the word <span class=\"cyan-text hl\">Christ</span> is concentrated within the Epistles!\n",
    "\n",
    "## Constructing the Network\n",
    "\n",
    "After obtaining the list of entities to analyze, we can begin constructing the network.\n",
    "\n",
    "### Vertices and Edges\n",
    "\n",
    "The first step is to determine the building blocks. Vertices can be defined as entities obtained in the previous chapter. For simplicity, an edge between two vertices A and B exists if the two are within a certain number of words near each other.\n",
    "\n",
    "Since connections can vary between acquaintances to best friends, it is also important to quantify the degree of connectivity between two vertices. To account for this, we will define two measures, intimacy and proximity.\n",
    "\n",
    "#### Intimacy\n",
    "\n",
    "Intimacy is the degree of closeness between two entities. A higher intimacy indicates that two entities are close, while a lower intimacy suggests that the two are mere acquaintances.\n",
    "\n",
    "Calculating intimacy involves the interplay of two factors: the degree of repetition and the number of words. If two entities are close to each other multiple times, then it is reasonable to suggest that they are closer than another two whose relationship is only stated once.\n",
    "\n",
    "In addition, for each time there is a connection, we also have to account for the number of words between them. A distance of 0 may imply that both entities are referring to the same person (Jesus Christ), while a longer distance may imply that both entities are several generations apart (Matthew 1).\n",
    "\n",
    "This measure is important when determining the position of each node in the graph.\n",
    "\n",
    "#### Proximity\n",
    "\n",
    "Proximity is similar to intimacy, except that a smaller proximity implies closeness, while a larger proximity suggests distance. It is calculated by taking the inverse of intimacy and is used to determine \"how near\" one entity is to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = inputs\n",
    "\n",
    "# Construction parameters\n",
    "intimacies = {}\n",
    "dist_l = 50\n",
    "decay = 0.25\n",
    "\n",
    "# Calculate the Degree of Intimacy\n",
    "# The closer the names are together, the higher the degree of intimacy\n",
    "# The more repetitions of names being close together, the higher the degree of intimacy\n",
    "# Loop Through Each Book\n",
    "for k, l in proper_noun_tokens.items():\n",
    "    # Loop Through Each Entity\n",
    "    for i in range(len(l)):\n",
    "        ind, ent = l[i]\n",
    "        # On a fixed entity, compare with neighboring entities\n",
    "        for i_hat in range(i+1, min(i+1+dist_l, len(l))):\n",
    "            ind_hat, ent_hat = l[i_hat]\n",
    "            # If the two entities are pretty close, create an edge connecting these two\n",
    "            if (abs(ind - ind_hat) <= dist_l and ent != ent_hat):\n",
    "                k = tuple(sorted([ent, ent_hat]))\n",
    "                if (k not in intimacies):\n",
    "                    intimacies[k] = np.exp(-1. * decay * abs(ind - ind_hat))\n",
    "                else:\n",
    "                    intimacies[k] += np.exp(-1. * decay * abs(ind - ind_hat))\n",
    "\n",
    "# Calculate proximity, which is the inverse of intimacy\n",
    "max_intimacy = max(intimacies.values())\n",
    "proximities = dict((k, 1. * max_intimacy / v) for k,v in intimacies.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Social Network\n",
    "\n",
    "Having defined the vertices and edges, we can now construct the social network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Graph\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(w for w,_ in vertices.items())\n",
    "sorted_vertices = sorted(vertices.items(), key=operator.itemgetter(1), reverse = True)\n",
    "\n",
    "G.add_weighted_edges_from((k[0], k[1], v) for k, v in intimacies.items())\n",
    "nx.set_edge_attributes(G, values=proximities, name=\"proximity\")\n",
    "\n",
    "\n",
    "\n",
    "############################### Plotly Construction ###########################\n",
    "\n",
    "# For illustrative purposes, let us show only the top 50 entities\n",
    "n_show = 50\n",
    "sub_G = G.subgraph(n for n, _ in sorted_vertices[:n_show])\n",
    "\n",
    "pos = nx.spring_layout(sub_G, k=3.0)\n",
    "\n",
    "############################### Prepare Vertices ##############################\n",
    "\n",
    "# Construct Vertices Information for Plotly\n",
    "v_plotly = {}\n",
    "for node in sub_G.nodes():\n",
    "    \n",
    "    # Create Hover Text\n",
    "    top_edges = sorted(G[node].items(),key=lambda v: v[1][\"proximity\"])[:5]\n",
    "    appearances = vertices[node]\n",
    "    connections = G.degree(node)\n",
    "    hovertext = \"<b>Name: </b>{}<br>\".format(node) + \\\n",
    "                \"<b>Word Appearances:</b> {:d}<br>\".format(appearances) + \\\n",
    "                \"<b># Connections:</b> {:d}<br>\".format(connections) + \\\n",
    "                \"<b>Closest Neighbors (and Proximity):</b><br>\" + \\\n",
    "                \"<br>\".join(\"{} ({:.0f})\".format(e[0], e[1][\"proximity\"]) for e in top_edges)\n",
    "    \n",
    "    v_plotly[node] = {\n",
    "        \"x\": pos[node][0],\n",
    "        \"y\": pos[node][1],\n",
    "        \"size\": min(vertices[node] / 500. * 30.,30),\n",
    "        \"color\": _d.fade_color(_d.txt_color,0.3),\n",
    "        \"hovertext\": hovertext,\n",
    "        \"rank\": 9999 # To determine which color to be plotted\n",
    "    }\n",
    "\n",
    "############################### Prepare Edges ##############################\n",
    "e_plotly = {}\n",
    "\n",
    "# Define Edge Groups for Plotly\n",
    "edge_groups = OrderedDict([\n",
    "    (\"Very Close (1-5)\", {\n",
    "        \"range\": [0, 5],\n",
    "        \"color\": _d.get_color(0),\n",
    "        \"linew\": 3.\n",
    "    }),\n",
    "    (\"Close (6-25)\", {\n",
    "        \"range\": [6, 25],\n",
    "        \"color\": _d.fade_color(_d.get_color(0),0.4),\n",
    "        \"linew\": 2.\n",
    "    }),\n",
    "    (\"Normal (26-75)\", {\n",
    "        \"range\": [26, 75],\n",
    "        \"color\": _d.fade_color(_d.get_color(0),0.2),\n",
    "        \"linew\": 1.\n",
    "    }),\n",
    "    (\"Far (76-100)\", {\n",
    "        \"range\": [76, 100],\n",
    "        \"color\": _d.fade_color(_d.get_color(0),0.1),\n",
    "        \"linew\": 0.75       \n",
    "    }),\n",
    "    (\"Very Far (>100)\", {\n",
    "        \"range\": [101, math.inf],\n",
    "        \"color\": _d.fade_color(_d.get_color(0),0.1),\n",
    "        \"linew\": 0.25       \n",
    "    })\n",
    "])\n",
    "\n",
    "def find_edge_group_item(proximity):\n",
    "    for k, v in edge_groups.items():\n",
    "        l_b, u_b = v[\"range\"]\n",
    "        if l_b <= proximity and proximity <= u_b:         \n",
    "            return (k, v)\n",
    "        \n",
    "# Construct Edges for Plotly\n",
    "for edge in sub_G.edges():\n",
    "    \n",
    "    # Get Distance and Group\n",
    "    proximity = int(G[edge[0]][edge[1]][\"proximity\"])\n",
    "    g_name, g_attrs = find_edge_group_item(proximity)\n",
    "    \n",
    "    # Positions\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    \n",
    "    e_plotly[edge[0] + \"-\" + edge[1]] = {\n",
    "        \"nodes\" : [edge[0], edge[1]],\n",
    "        \"x\": [x0, x1],\n",
    "        \"y\": [y0, y1],\n",
    "        \"group\": g_name,\n",
    "        \"color\": g_attrs[\"color\"],\n",
    "        \"linewidth\": g_attrs[\"linew\"],\n",
    "        \"proximity\": proximity\n",
    "    }\n",
    "    \n",
    "    # Update Information on Vertices End\n",
    "    v_plotly[edge[0]][\"rank\"] = min(proximity, v_plotly[edge[0]][\"rank\"])\n",
    "    v_plotly[edge[1]][\"rank\"] = min(proximity, v_plotly[edge[1]][\"rank\"])\n",
    "  \n",
    "\n",
    "# Update Vertices Color Based on Ranking\n",
    "for k, v in v_plotly.items():\n",
    "    _, g_attr = find_edge_group_item(v[\"rank\"])\n",
    "    v[\"color\"] = g_attr[\"color\"]\n",
    "\n",
    "############################### Draw Elements ##############################\n",
    "# Create Elements For Plotly\n",
    "data = []\n",
    "\n",
    "# Edges First So That Vertices Are In Front of Nodes\n",
    "for k,v in sorted(e_plotly.items(), key=lambda e: e[1][\"proximity\"], reverse=True):\n",
    "    data.append(py_go.Scatter(\n",
    "        mode=\"lines\",\n",
    "        line=py_go.scatter.Line(\n",
    "            width=v[\"linewidth\"],\n",
    "            color=v[\"color\"]\n",
    "        ),\n",
    "        \n",
    "        x=v[\"x\"],\n",
    "        y=v[\"y\"],\n",
    "        \n",
    "        legendgroup=v[\"group\"],\n",
    "        showlegend = False,\n",
    "        \n",
    "        hoverinfo=\"none\"\n",
    "    ))\n",
    "    \n",
    "# Vertices Next\n",
    "data.append(py_go.Scatter(\n",
    "    mode='markers+text',\n",
    "    marker=py_go.scatter.Marker(\n",
    "        color=[v[\"color\"] for _,v in v_plotly.items()],\n",
    "        size=[v[\"size\"] for _,v in v_plotly.items()]),\n",
    "    textposition='bottom center',\n",
    "    \n",
    "    x=[v[\"x\"] for _,v in v_plotly.items()],\n",
    "    y=[v[\"y\"] for _,v in v_plotly.items()],\n",
    "    text=[k for k in v_plotly.keys()],\n",
    "    \n",
    "    showlegend = False,\n",
    "    \n",
    "    hoverinfo='text',\n",
    "    hovertext= [v[\"hovertext\"] for _,v in v_plotly.items()]\n",
    "))\n",
    "\n",
    "# Append Legends\n",
    "data.append(py_go.Scatter(\n",
    "                name=\"Proximity\",\n",
    "                mode=\"none\",\n",
    "                x = [0,0], y = [0,0],\n",
    "\n",
    "                showlegend = True,\n",
    "\n",
    "                hoverinfo=\"none\"\n",
    "            ))\n",
    "\n",
    "data.extend([ py_go.Scatter(\n",
    "                name=k,\n",
    "                mode=\"lines\",\n",
    "                line=py_go.scatter.Line(\n",
    "                    color=v[\"color\"]\n",
    "                ),        \n",
    "                x = [0,0], y = [0,0],\n",
    "\n",
    "                legendgroup = k,\n",
    "                showlegend = True,\n",
    "    \n",
    "                hoverinfo=\"none\"\n",
    "            ) for k, v in edge_groups.items() ])  \n",
    "\n",
    "# Layouts\n",
    "layout = py_go.Layout(_d.py_layout)\n",
    "layout[\"title\"] = \"Social Network of Top \" + str(n_show) + \" Entities in The Bible\"\n",
    "layout[\"width\"] = 700\n",
    "layout[\"height\"] = 475\n",
    "layout[\"hovermode\"]='closest'\n",
    "layout[\"xaxis\"] = py_go.layout.XAxis(showgrid=False, zeroline=False, showticklabels=False)\n",
    "layout[\"yaxis\"] = py_go.layout.YAxis(showgrid=False, zeroline=False, showticklabels=False)\n",
    "fig = py_go.Figure(data=data,layout=layout)\n",
    "\n",
    "py.iplot(fig, config=_d.py_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart provides a bird's eye view of the social network. Some of these relationships are expected, such as how <span class=\"hl\">God, Jehovah, Lord, Jesus</span> and <span class=\"hl\">Christ</span> are closely interconnected to each other. Some relationships are surprising when compared to another. (For example, <span class='hl'>Moses</span> has a closer proximity to God than both <span class='hl'>Abraham</span> and <span class='hl'>David</span>.) It is also interesting to see some of the lesser-known relationships surfacing in the network (e.g. Joseph's children, <span class='hl'>Ephraim</span> and <span class='hl'>Manasseh</span>).\n",
    "\n",
    "It can be extremely difficult to digest information just by referencing the chart above. In the next section, we will be studying the network by compressing the information into more palatable formats.\n",
    "\n",
    "#### How Close is Each Entity to God?\n",
    "\n",
    "One important application of social network analysis is the ability to understand how \"close\" you are to other strangers. For example, suppose you wanted to pass a letter to the President through \"a friend-of-a-friend approach\". How many intermediaries must the letter be passed to before reaching the President? This number is what psychologist Stanley Migram defines as the degree of separation between you and the President. According to his <a href=\"https://en.wikipedia.org/wiki/Small-world_experiment\" target=\"_blank\">small-world experiment</a>, any two people can be connected via a maximum of <span class=\"hl\">six degrees of separation</span>.\n",
    "\n",
    "In this section, we will study how close an entity is to the most important person in the bible - <span class=\"hl\">God</span>. This is done through calculating the shortest path between God and the entity in focus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Entities' Proximity To Each Other\n",
    "def get_proximities():\n",
    "    return dict(nx.all_pairs_dijkstra_path_length(G, weight='proximity'))\n",
    "proximity_to = _h.cache(get_proximities, \"all_dijkstra_paths\")\n",
    "\n",
    "# Parameters:\n",
    "root_node=\"God\"\n",
    "max_distance = 150\n",
    "horizontal_nodes = ['God','Jehovah','Israel','Lord','Jesus','Moses']\n",
    "max_size_highlight = 30\n",
    "exclude_highlight_nodes = ['Nazareth','Saviour','Redeemer','Haggai']\n",
    "\n",
    "\n",
    "to_root = proximity_to[root_node]\n",
    "\n",
    "# Find Entities that are Within max_distance distances away from root node\n",
    "to_root_sorted = sorted(to_root.items(), key=operator.itemgetter(1))\n",
    "to_root_sorted = [(k,v) for k,v in to_root_sorted if v <= max_distance]\n",
    "\n",
    "# Create Graph\n",
    "G_to_root = nx.DiGraph()\n",
    "G_to_root.add_node(root_node)\n",
    "for k,v in to_root_sorted:\n",
    "    nx.add_path(G_to_root,nx.dijkstra_path(G,root_node,k, \"proximity\"))\n",
    "\n",
    "# Determine Positions For Each Node\n",
    "def get_width(n):\n",
    "    # Base Case: Leaf of Tree\n",
    "    if (not G_to_root[n]):\n",
    "        return 1\n",
    "    else:\n",
    "        width = 0\n",
    "        for neighbor in G_to_root[n].keys():\n",
    "            width += get_width(neighbor)\n",
    "        return width\n",
    "\n",
    "pos = {}\n",
    "def get_position(root=root_node, start=0., width=100.):\n",
    "\n",
    "    pos[root] = (start + width / 2.,-1.*to_root[root])\n",
    "    neighbors = sorted(G_to_root[root].keys(), key=lambda k: to_root[k])\n",
    "    widths = dict((n,get_width(n)) for n in neighbors)\n",
    "    total_width = sum(widths.values())\n",
    "\n",
    "    s = start\n",
    "    for n in neighbors:\n",
    "        get_position(n, s, widths[n] / total_width * width)\n",
    "        s += widths[n] / total_width * width\n",
    "\n",
    "get_position() \n",
    "\n",
    "# Plot on matplotlib\n",
    "plt.figure(figsize=(30,12))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.title(\"Proximity to \" + root_node)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "plt.xticks([])\n",
    "\n",
    "plt.ylabel(\"Proximity to \" + root_node)\n",
    "plt.yticks(range(0,-1 * max_distance,-20),range(0, max_distance,20))\n",
    "\n",
    "# Plot edges\n",
    "highlighted_nodes = [ k for k in G_to_root.nodes() if vertices[k] <= max_size_highlight and k not in exclude_highlight_nodes]\n",
    "\n",
    "def plot_edges(root=root_node):\n",
    "    for n in G_to_root[root].keys():\n",
    "        plot_edges(n)\n",
    "        is_highlighted = any(nx.has_path(G_to_root,n,hn) for hn in highlighted_nodes)\n",
    "        plt.plot([pos[root][0],pos[n][0],pos[n][0]],\n",
    "                 [pos[root][1],pos[root][1],pos[n][1]],\n",
    "                color=_d.get_color(0) if is_highlighted else _d.fade_color(_d.txt_color,0.3),\n",
    "                linewidth= 2. if is_highlighted else 1.)\n",
    "plot_edges()\n",
    "\n",
    "# Plot vertices\n",
    "def plot_vertices():\n",
    "    for n, p in pos.items():\n",
    "\n",
    "        if (n in highlighted_nodes):\n",
    "            bg_color = _d.get_color(0)\n",
    "            color = _d.bg_color\n",
    "            prefix = \" \"\n",
    "            pad = 2\n",
    "        else:\n",
    "            if (any(nx.has_path(G_to_root,n,hn) for hn in highlighted_nodes)):\n",
    "                color = _d.get_color(0)\n",
    "            else:\n",
    "                color = _d.fade_color(_d.txt_color,0.5)\n",
    "            bg_color = _d.bg_color + \"dd\"\n",
    "            prefix = \"\"\n",
    "            pad = 1\n",
    "\n",
    "        plt.text(p[0],p[1],prefix + n,\n",
    "                 size = 25,\n",
    "                 rotation=0 if n in horizontal_nodes else 90,\n",
    "                 ha='center',va='center',\n",
    "                 bbox={'facecolor': bg_color,'edgecolor':'none','pad': pad},\n",
    "                 color=color)\n",
    "plot_vertices()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree above shows entities which are within 150 distances away from God. Unsurprisingly, a lot of the major characters in the bible have close relationships with God (<span class=\"hl\">Jesus, Moses, David, Abraham</span>). \n",
    "\n",
    "However, we also notice some lesser-known entities which are closely connected to God:\n",
    "\n",
    "* <span class=\"hl\">Michal</span> was the youngest daughter of King Saul and the first wife of David. (<a href=\"https://www.bible.com/bible/12/1SA.18.18-27\" target=\"_blank\">1 Samuel 18:18-27</a>)\n",
    "* <span class=\"hl\">Ornan</span> provided a threshing floor for David to build his altar on. (<a href=\"https://www.bible.com/bible/12/1CH.21.18-25\" target=\"_blank\">1 Chronicles 21:18-25</a>)\n",
    "* <span class=\"hl\">Nun</span> was the father of Joshua, who led the Israelites to the promised land. (<a href=\"https://www.bible.com/bible/12/EXO.33.10-11\" target=\"_blank\">Exodus 33:10-11</a>)\n",
    "* <span class=\"hl\">Hiram</span>, King of Tyre, provided Solomon with the cedar and fir for the construction of the Lord's Temple. (<a href=\"https://www.bible.com/bible/12/1KI.5.1-12\" target=\"_blank\">1 Kings 5:1-12</a>)\n",
    "* <span class=\"hl\">Horeb</span> is the mountain where Moses encountered the burning bush. (<a href=\"https://www.bible.com/bible/12/EXO.3.1-2\" target=\"_blank\">Exodus 3:1-2</a>)\n",
    "* <span class=\"hl\">Manoah</span> was the father of Samson. (<a href=\"https://www.bible.com/bible/12/JDG.13.1-5\" target=\"_blank\">Judges 13:1-5</a>)\n",
    "* <span class=\"hl\">Nebat</span> was Jeroboam's father, a king over the Northern Kingdom of Israel who disobeyed the Lord. (<a href=\"https://www.bible.com/bible/12/1KI.11.26-28\" target=\"_blank\">1 Kings 11:26-28</a>)\n",
    "* <span class=\"hl\">Baasha</span> killed Nadab, Jeroboam's successor, to succeed him as king. (<a href=\"https://www.bible.com/bible/12/1KI.15.25-32\" target=\"_blank\">1 Kings 15:25-32</a>)\n",
    "\n",
    "#### How Much Influence Does Each Entity Have?\n",
    "\n",
    "Another important application of social network analysis is the ability to understand which individuals yield the most influence. For example, suppose you would like someone to post an endorsement video on YouTube. Which individual should you seek to get the highest number of views? Typically, these individuals should be closely connected to a large group of people and have many ardent followers. \n",
    "\n",
    "Similarly, we would like to investigate which biblical entities hold a strong influence. To calculate influence, let us first assume that we pass a message to A. How many other entities would receive the message? This would likely depend on the proximity of A to the others in the network. To translate this into code, we first calculate the shortest paths from A to every other entity. The shortest paths are then transformed into the probability of receiving the message via the exponential function. These probabilities, one for each node, are then summed to obtain the expected number of entities receiving the message, which we define as <span class=\"hl\">Influence Level</span>.  \n",
    "\n",
    "After calculating the influence level of each node, we subsequently cluster them using <a href=\"https://spin.atomicobject.com/2015/05/26/mean-shift-clustering\" target=\"_blank\">Mean Shift Algorithm</a> to produce the chart below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that for evey 50 distances, the chances of information being passed on gets reduced\n",
    "# by 50%\n",
    "half_life = 50\n",
    "inf_decay = math.log(2) / half_life \n",
    "\n",
    "influence = {}\n",
    "for k, v in proximity_to.items():\n",
    "    influence[k] = sum(math.exp(-1. * inf_decay * v1) for _, v1 in v.items())\n",
    "\n",
    "# Cluster influences using MeanShift (with flat kernel and adjusted bandwidth)\n",
    "#https://spin.atomicobject.com/2015/05/26/mean-shift-clustering/\n",
    "#https://stackoverflow.com/questions/35094454/how-would-one-use-kernel-density-estimation-as-a-1d-clustering-method-in-scikit\n",
    "sorted_influence = sorted(influence.items(),key=operator.itemgetter(1), reverse=True)\n",
    "ms = MeanShift(bandwidth=2.5)\n",
    "ms.fit(np.array([v for _,v in sorted_influence]).reshape(-1,1))\n",
    "cluster_ind = ms.labels_\n",
    "# Reorder clusters based on influence\n",
    "cluster_set = []\n",
    "for c_i in cluster_ind:\n",
    "    if c_i not in cluster_set:\n",
    "        cluster_set.insert(0,c_i)\n",
    "cluster_ind = [cluster_set.index(c_i) for c_i in cluster_ind]\n",
    "clusters = {}\n",
    "# Add Groupings\n",
    "for c_i in np.unique(cluster_ind):\n",
    "    clusters[c_i] = [sorted_influence[i] for i in range(len(sorted_influence)) if cluster_ind[i] == c_i]\n",
    "\n",
    "# Create Color Palette for Clusters\n",
    "color_pal = _d.get_color(\"palette\")(len(cluster_set)-1)\n",
    "def get_cluster_color(group):\n",
    "    if (group == 0):\n",
    "        return _d.fade_color(_d.ltxt_color,0.1)\n",
    "    else:\n",
    "        return _d.fade_color(_d.get_color(0),0.2 + (1.0-0.2) * group / max(cluster_set))\n",
    "\n",
    "# Plot    \n",
    "plt.figure(figsize=(30,6))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.title(\"Influential Entities\")\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.yticks([])\n",
    "plt.ylim([-1.2, 1.2])\n",
    "plt.xlim([45, 0])\n",
    "plt.xlabel(\"Influence Level\")\n",
    "\n",
    "entities_to_highlight = [\"Hebron\",\"Joab\",\"Ahab\",\"Zedekiah\",\"Asa\",\"Jehoshaphat\"]\n",
    "\n",
    "for c_i in np.unique(cluster_ind):\n",
    "    \n",
    "    cluster_values = [v for _,v in clusters[c_i]]\n",
    "    \n",
    "    # Plot Lines\n",
    "    if (c_i == 0):\n",
    "        min_x = min(cluster_values)\n",
    "        plt.arrow(min_x,0,-0.05,0, \n",
    "                  head_width=0.05, head_length=0.5,\n",
    "                  edgecolor=get_cluster_color(c_i),\n",
    "                  facecolor=get_cluster_color(c_i))\n",
    "    else:\n",
    "        min_x = min(cluster_values)-(min(cluster_values) - max(v for _,v in clusters[c_i-1]))/2. + 0.1\n",
    "        plt.plot([min_x, min_x],[-0.1,0.1], color=get_cluster_color(c_i))\n",
    "    \n",
    "    if (c_i == max(cluster_ind)):\n",
    "        max_x = max(cluster_values)\n",
    "        plt.arrow(max_x-0.5,0,0.05,0, \n",
    "                  head_width=0.05, head_length=0.5,\n",
    "                  edgecolor=get_cluster_color(c_i),\n",
    "                  facecolor=get_cluster_color(c_i))\n",
    "    else:\n",
    "        max_x = max(cluster_values) + (min(v for _,v in clusters[c_i+1])-max(cluster_values))/2. - 0.1\n",
    "        plt.plot([max_x, max_x],[-0.1,0.1], color=get_cluster_color(c_i))\n",
    "    plt.plot([min_x, max_x],[0,0],color=get_cluster_color(c_i))\n",
    "    \n",
    "    # Plot Text\n",
    "    cluster_texts = [k for k,_ in clusters[c_i]][:10]\n",
    "    cutoff = math.ceil(len(cluster_texts)/2)\n",
    "    for i in range(len(cluster_texts)):\n",
    "        if cluster_texts[i] in entities_to_highlight:\n",
    "            bg_color = get_cluster_color(c_i)\n",
    "            fg_color = _d.bg_color\n",
    "        else:\n",
    "            bg_color = _d.bg_color\n",
    "            fg_color = get_cluster_color(c_i)\n",
    "        plt.text((min_x + max_x)/2.,\n",
    "                 (cutoff - i - (1 if i >= cutoff else 0))*0.2,\n",
    "                 cluster_texts[i],\n",
    "                 size = 25,\n",
    "                 ha='center',va='center',\n",
    "                 bbox={'facecolor': bg_color,'edgecolor':'none','pad': 2},\n",
    "                 color=fg_color)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, <span class=\"hl\">Jehovah, God and Jesus</span> belong to the top 2 most influential groups in the bible. However, as in the previous section, we noticed some minor entities which are somewhat influential (highlighted above):\n",
    "\n",
    "* <span class=\"hl\">Hebron</span> is a location. Abraham lived there when he and Lot separated. (<a href=\"https://www.bible.com/bible/59/GEN.13.1-18\" target=\"_blank\">Genesis 13</a>)\n",
    "* <span class=\"hl\">Joab</span> was one of David's commanders. (<a href=\"https://www.bible.com/bible/59/2SA.8.15-18\" target=\"_blank\">2 Samuel 8:15-18</a>)\n",
    "* <span class=\"hl\">Ahab</span> was the presiding king during the time of Elijah. (<a href=\"https://www.bible.com/bible/59/1KI.16.29-34\" target=\"_blank\">1 Kings 16:29-34</a>)\n",
    "* <span class=\"hl\">Zedekiah</span> was the last king of Judah prior to its destruction to Babylon. (<a href=\"https://www.bible.com/bible/59/JER.52.1-11\" target=\"_blank\">Jeremiah 52:1-11</a>)\n",
    "* <span class=\"hl\">Asa</span> was the third king of Judah and \"did what was good and right in the eyes of the Lord his God.\" (<a href=\"https://www.bible.com/bible/59/2CH.14.1-4\" target=\"_blank\">2 Chronicles 14:1-4</a>)\n",
    "* <span class=\"hl\">Jehoshaphat</span> was the son of Asa and the fourth king of Judah. He worshipped the Lord and did not seek false idols. (<a href=\"https://www.bible.com/bible/59/2CH.17.1-19\" target=\"_blank\">2 Chronicles 17:1-19</a>)\n",
    "\n",
    "#### Which Community Does Each Entity Reside In?\n",
    "\n",
    "A community is a group of individuals that interact frequently with one another. In real life, this can be your family, colleagues, or friends. Similarly, we would like to discover the existence of such communities in the bible. We suspect that there will be at least one large community due to God's connections, as well as some isolated ones. For the purposes of this study, such extremely small and large communities will be excluded from the analysis.\n",
    "\n",
    "Listed below are some communities of interest we detected through <a data-toggle=\"popover\" title=\"\" data-content=\"The determination of groups through node labeling. Algorithm is initialized by labeling each node with its name. In each iteration, the label is updated with one of the neighbor's (in particular, the one that is connected by the highest weight). This propagation continues on until the labels of all nodes have reached an equilbrium (i.e. do not change). Upon completion, nodes with the same labels are grouped as a community.\" data-original-title=\"Label Propagation\">label propagation techniques</a>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Community Using Label Propagation\n",
    "def get_communities():\n",
    "    random.seed(241)\n",
    "    return nx.algorithms.community.asyn_lpa_communities(G.subgraph(n for n, v in vertices.items() if v>=5), weight=\"weight\")\n",
    "communities = _h.cache(get_communities, \"all_communities\")    \n",
    "    \n",
    "output = []\n",
    "for d in communities:\n",
    "    if 5 <= len(d) and len(d) < 10:\n",
    "        output.append(d)\n",
    "\n",
    "output = sorted(output, key=lambda l: len(l))\n",
    "for d in output:\n",
    "    print(\"Community \" + str(output.index(d) + 1) + \": \" + \", \".join(sorted(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Community 1 corresponds to the Jesus's apostles. (<a href=\"https://www.bible.com/bible/59/MAT.10.2-3\" target=\"_blank\">Matthew 10:2-3</a>)\n",
    "* Community 2 corresponds to the lineage from Shem, Noah's son, to Abraham. (<a href=\"https://www.bible.com/bible/59/GEN.10.21-26\" target=\"_blank\">Genesis 10:21-26</a> and <a href=\"https://www.bible.com/bible/59/GEN.11.10-26\" target=\"_blank\">Genesis 11:10-26</a>)\n",
    "* Community 3 corresponds to Paul's encounters in his missionary journeys, as described in Acts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 3\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "nx.draw_circular(G.subgraph(output[ind-1]),\n",
    "                 with_labels=True,\n",
    "                 node_color=_d.bg_color,\n",
    "                 node_size = 1000,\n",
    "                 node_shape = 's',\n",
    "                 edge_color = _d.fade_color(_d.txt_color, 0.2),\n",
    "                 font_family = _d.def_font,\n",
    "                 font_size = 15,\n",
    "                 font_color = _d.txt_color\n",
    "                )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Community 4 corresponds to Esau's lineage. (<a href=\"https://www.bible.com/bible/59/1CH.1.38-40\" target=\"_blank\">1 Chronicles 1:38-40</a>)\n",
    "\n",
    "## Summary of Results\n",
    "\n",
    "By detecting entities using Part-Of-Speech tagging and determining connections through word proximities, we have successfully constructed a social network for the bible. A quick dive into the network also provides insights of minor characters that is often overlooked:\n",
    "\n",
    "* <span class=\"hl\">Michal</span>, <span class=\"hl\">Ornan</span>, <span class=\"hl\">Nun</span>, <span class=\"hl\">Hiram</span>, <span class=\"hl\">Horeb</span>, <span class=\"hl\">Manoah</span>, <span class=\"hl\">Nebat</span> and <span class=\"hl\">Baasha</span> have closer proximities to God than expected.\n",
    "* <span class=\"hl\">Hebron</span>, <span class=\"hl\">Joab</span>, <span class=\"hl\">Ahab</span>, <span class=\"hl\">Zedekiah</span>, <span class=\"hl\">Asa</span> and <span class=\"hl\">Jehoshaphat</span> have higher influences but are lesser-known.\n",
    "* Through the search of communities, we have discovered the main characters across Paul's missionary journeys.\n",
    "\n",
    "## Limitations\n",
    "\n",
    "The approach described in this project is relatively simple, and by no means perfect. To construct the network more accurately, we will need to build a more robust entity-detection algorithm, as well as a more intricate edge definition. Some future works for this project include:\n",
    "\n",
    "* <span class=\"hl\">Name Disambiguation</span>: There may be some names which are the same, but corresponding to different individuals. One example would be King Saul and Saul of Tarsus (Paul).\n",
    "* <span class=\"hl\">Name Matching</span>: At the same time, there are some entities which are represented by different names (Abraham and Abram). Merging these two entities into one may provide a more accurate representation of the character's connections with others.\n",
    "* <span class=\"hl\">Pronoun Disambiguation</span>: This is a difficult task, but can potentially provide a huge leap in accuracy. For example, the Epistles genre are letters written by an author, hence there is a significant usage of the word \"I\". Replacing these pronouns with the actual entity will uncover numerous relationships that were overlooked.\n",
    "* <span class=\"hl\">Distance Definition</span>: We currently define the existence of a relationship if two words are near each other. Perhaps there could be a better way of defining this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
